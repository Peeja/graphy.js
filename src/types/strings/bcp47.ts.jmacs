@.{
	const bcp47 = await import('bcp-47');

	const F_NOOP = () => {};
	const F_IDENT = w => w;
	const F_TRUE = w => true;
	const plainify = (h_input, {filter:f_filter=F_TRUE}={}) => Object
		.entries(h_input)
		.filter(f_filter)
		.reduce((a_out, [si_key, w_value]) => [
			...a_out,
			`${si_key}:${JSON.stringify(w_value)}`,
		], [])
		.join(', ');
}

import type {
	Any,
	Union,
	List,
	String,
} from 'ts-toolbelt';

import type {
	Cast,
	Contains,
	Key as AnyKey,
	KnownKeys,
	Equals,
	Extends,
	Try,
	Type,
} from 'ts-toolbelt/out/Any/_api';

import type {
	And,
	Not,
	Or,
	Xor,
} from 'ts-toolbelt/out/Boolean/_api';

import type {
	If,
} from 'ts-toolbelt/out/Any/If';

import type {
	Remove,
	KeySet,
	Length,
} from 'ts-toolbelt/out/List/_api';

import type {
	Merge,
} from 'ts-toolbelt/out/Object/_api';

import type {
	Greater,
	GreaterEq,
	Lower,
	LowerEq,
	Range,
	Add,
	Sub,
} from 'ts-toolbelt/out/Number/_api';

import type {
	Join,
	Split,
} from 'ts-toolbelt/out/String/_api';

import type {
	False,
	True,
	Bool,
	Debug,
	ASSERT_TRUE,
	ASSERT_SAME,
	ASSERT_VOID,
	ASSERT_NEVER,
} from '../utility'

import type {
	ALPHA,
	ALPHA_LOWER,
	ALPHA_UPPER,
	ALPHA_ANY,
	DIGIT,
	ALPHANUM,
} from './util';


declare const debug_info: unique symbol;


type StrLen<Input extends string> = String.Length<Input>;


@.{
	Object.defineProperties([].__proto__, {
		strs: {
			get() {
				return this.map(s => `'${s}'`);
			},
		},
		or: {
			get() {
				return this.join(' | ');
			},
		},
	});

	Object.defineProperties(''.__proto__, {
		$: {
			get() {
				return `\$\{${this}}`;
			},
		},
		opt: {
			get() {
				return `''|\`${this}\``.$;
			},
		},
		star: {
			get() {
				return `RepeatStar<\`${this}\`>`.$;
			},
		},
		times: {
			value(n_lower, n_upper=-1) {
				const s_embed = this;
				let s_out = s_embed.repeat(n_lower);
				let s_upper = '';
				for(let i_recurse=n_lower; i_recurse<n_upper; i_recurse++) {
					s_upper = (s_embed+s_upper).opt;
				}
				return s_out+s_upper;
			},
		},
	});

	const ode = Object.entries;

	function numeric(i_lo, i_hi) {
		const a_chars = [];
		for(let i_num=i_lo; i_num<=i_hi; i_num++) {
			a_chars.push(`${i_num}`);
		}
		return a_chars.join('|');
	}
}


type SINGLETON = Exclude<ALPHANUM, 'x'>;

// type RepeatStar<TypeString extends string> = '' | `${TypeString}${Repeat<TypeString>}`;
// type RepeatPlus<TypeString extends string> = `${TypeString}${RepeatStar<TypeString>}`;


type Regular = 'art-lojban' | 'cel-gaulish' | 'no-bok' | 'no-nyn' | 'zh-guoyu'
	| 'zh-hakka' | 'zh-min' | 'zh-min-nan' | 'zh-xiang';

type Irregular = 'en-GB-oed' | 'i-ami' | 'i-bnn' | 'i-default' | 'i-enochian' | 'i-hak'
	| 'i-klingon' | 'i-lux' | 'i-mingo' | 'i-navajo' | 'i-pwn' | 'i-tao' | 'i-tay' | 'i-tsu'
	| 'sgn-BE-FR' | 'sgn-BE-NL' | 'sgn-CH-DE';



type Invalid<
	Hint extends any=any,
> = {
	[debug_info]: Hint,
} | {
	[assertion_err]: Hint,
};

type Stringify2<
	Input extends any,
> = Input extends string
	? Input
	: (Input extends number | bigint | boolean | null | undefined
		? `${Input}`
		: (Input extends any[]
			? '...'
			: (Input extends object
				? `{${ToString<KnownKeys<Input>>}}`
				: '{unknown}'
			)
		)
	);

type ToString<
	Input extends any,
> = Input extends string | number | bigint | boolean | null | undefined
	? `${Input}`
	: (Input extends symbol
		? 'Symbol()'
		: '{unknown}'
	);

type StringifyList<
	a_strings extends any[],
> = Cast<{
	[K in keyof a_strings]: `${Stringify<a_strings[K]>}`
}, string[]>

type Stringify<
	Input extends any,
	MaxDepth extends 0|1|2|3|4|5|6=6,
> = Input extends string
	? Input
	: (Input extends number | bigint | boolean | null | undefined
		? `${Input}`
		: (Input extends any[]
			// ? (Lower<MaxDepth, 1> extends True
			// 	? '...'
			// 	: `[${Join<Union.ListOf<`'${Stringify2<Input[number], Sub<MaxDepth, 1>>}'`>, ', '>}]`
			// ? `[${Join<Union.ListOf<`'${Stringify2<Input[number]>}'`>, ', '>}]`
			? `[${Join<StringifyList<Input>>}]`
			: (Input extends object
				? `{${ToString<KnownKeys<Input>>}}`
				: '{unknown}'
			)
		)
	);

{
	type TEST = Stringify<['a', 'b', 'c']>;
}


// type StringifyList<
// 	Input extends any[],
// > = `[${Join<ListOf<`'${ToString<Input[number]>}'`, ', '>>}]`;

declare const assertion_err: unique symbol;

type AssertionError<
	A extends any,
	Info extends any,
> = {
	[assertion_err]: Info;
} & A;

@.{

	const escape_ts = (sj_ts, b_no_infer=false) => {
		let sj_rep = (sj_ts+'')
			.replace(/([`$])/g, '\\$1')

		if(!b_no_infer) {
			sj_rep = sj_rep
				// replace string inference
				.replace(/^(.*?) extends (?:\\`)?\\\$\{(?:infer\s+)?([^}]+)}(?:\\`)?\s*$/g, '$2 := $1 = \'${$2}\'')
				// replace direct inference
				.replace(/^(.*?) extends infer (\w+)/, '$2 := $1 = ${Cast<$1, string>}')
				// .replace(/infer (\w+)/g, '${AsString<$1>}')
				// .replace(/ extends /, ' is ');

				.replace(/(?:\\`)?\\\$\{(?:infer\s+)?([^}]+)}(?:\\`)?/g, '\'${$1}\'');
		}
		else {
			sj_rep = sj_rep
				.replace(/^(.*?) extends infer (\w+)/, '$2 := $1')
				// .replace(/infer (\w+)/g, '${AsString<$1>}')
				// .replace(/ extends /, ' is ');
		}

		return sj_rep;
	};

	const H_FILLS = {
		'a-z': 'ALPHA_LOWER',
	};

	const stringify_ts = (z_ts) => {
		if('string' === typeof z_ts) {
			return z_ts;
		}
		else if(Array.isArray(z_ts)) {
			return `[${z_ts.map(w => stringify_ts(w)).join(', ')}]`;
		}
		else {
			return `unknown`;
		}
	};

	const $ELSE = Symbol('else');

	const $ASSERTIONS = Symbol('assertions');


	const recurse_expand = (a_conditions, w_actions, h_append={}) => () => ({
		[a_conditions[0]]: a_conditions.length > 1? recurse_expand(a_conditions.slice(1), w_actions): w_actions,
		...h_append,
	});

	let i_assertion_error = 0;

	class Coder {
		constructor(s_language) {
			this._s_language = s_language;
			this._nl_indent = 1;
		}

		nl(nl_indent=0) {
			this._nl_indent += nl_indent;
			return '\n'+'\t'.repeat(this._nl_indent);
		}

		incr(sj_code) {
			return `\n${'\t'.repeat(this._nl_indent-1)}${sj_code.split(/\n/g).map(s => `\t\t${s}`).join('\n')}`;
		}

		assign(si_var, sj_expr) {
			return `${sj_expr} extends infer ${si_var}`;
		}

		cassign(si_var, sj_expr) {
			const [, sj_var, s_cast] = /^([\w0-9_$]+)(?:<([^>]+)>)?$/.exec(si_var);
			return [
				`${sj_expr} extends infer ${sj_var}`,
				`${sj_var} extends ${s_cast}`,
			];
		}

		assign_str(si_var, sj_expr) {
			return `${sj_expr} extends \`\${infer ${si_var}}\``;
		}

		switch_(sj_expr, si_var, h_cases) {
			return {
				[sj_expr]: () => Object.entries(h_cases)
					.reduce((h_out, [sj_case, w_case]) => ({
						...h_out,
						[`${si_var} extends ${sj_case}`]: w_case,
					}), $ELSE in h_cases
						? {[$ELSE]: h_cases[$ELSE]}
						: {}),
			};
		}

		switch_eq(sj_expr, si_var=`z_${sj_expr.replace(/^a-z/g, '').toLowerCase()}`, h_cases) {
			return this.switch_(`${sj_expr} extends infer ${si_var}`, si_var, h_cases);
		}

		switch_str(sj_expr, si_var=`s_${sj_expr.replace(/^a-z/g, '').toLowerCase()}`, h_cases) {
			return this.switch_(`${sj_expr} extends \`\${infer ${si_var}}\``, si_var, h_cases);
		}

		and(a_conditions) {
			const nl_conditions = a_conditions.length;
			if(!nl_conditions) return 'True';
			if(1 === nl_conditions) return a_conditions[0];

			// return `And<${this.nl(1)}${a_conditions[0]},${this.nl()}${and(a_conditions.slice(1))}${this.nl(-1)}>`;
			return [
				'And<', this.nl(1),
					a_conditions[0]+',', this.nl(),
					this.and(a_conditions.slice(1)), this.nl(-1),
				'>',
			].join('')
		}

		match_str(si_var, a_pattern) {
			return this.and(a_pattern
				.map((s_pattern, i_char) => `Extends<String.At<${si_var}, ${i_char}>, ${s_pattern}>`)
			)+' extends True';
		}

		if_(sj_condition, sj_then, sj_else, s_comment='') {
			sj_condition = sj_condition.replace(/\?$/, ' extends True');

			return [
				// this.nl(),
				// '(', this.incr(sj_condition), this.nl(1),
				'(', sj_condition, this.nl(1),
					...s_comment? [`// ^^ ${s_comment.replace(/\n/g, ' ')}`, this.nl()]: [],
					'\t? ', sj_then, this.nl(),
					'\t: ', sj_else, this.nl(-1),
				')',
			].join('');
		}

		compile_struct(h_struct, a_path=['/']) {
			let h_append = {};

			let s_assertion_input = 's_input';
			const gc_assertion = h_struct[$ASSERTIONS];
			if(gc_assertion) {
				if('string' === typeof gc_assertion.input) {
					s_assertion_input = gc_assertion.input;
				}

				h_append[$ASSERTIONS] = gc_assertion;
			}

			// refactor
			{
				const a_refactor = [];
				let b_refactored = false;

				for(const [s_conditions, w_actions] of ode(h_struct)) {
					const a_conditions = s_conditions.split('\0');
					if(a_conditions.length > 1) {
						b_refactored = true;
						a_refactor.push([
							a_conditions[0],
							recurse_expand(a_conditions.slice(1), w_actions, h_append),
						]);
					}
					else {
						a_refactor.push([s_conditions, w_actions]);
					}
				}

				if(b_refactored) {
					return this.compile_struct(a_refactor.reduce((h_out, [si_key, w_value]) => ({
						...h_out,
						[si_key]: w_value,
					}), {
						...h_append,
						...(h_struct[$ELSE]? {[$ELSE]:h_struct[$ELSE]}: {}),
					}), a_path);
				}
			}

			const i_condition = i_assertion_error++;

			let s_out = [`AssertionError<string, {`,
				`assertion_id: ${i_condition};`,
				`path: [${a_path.map(s => `\`${escape_ts(s)}\``).join(', ')}];`,
				`false: \`${escape_ts(Object.keys(h_struct).reverse().slice(-1) || '', true)}\`;`,
				`input: ${s_assertion_input};`,
				`scope: {
					${[...new Set(Object.keys(h_struct)
						.map(sj => sj.replace(/^(.*?) extends .*$/, '$1').replace(/\n\s*/g, ' ')))]
						.reduce((a_out, sj) => [
							...a_out,
							`'${sj.replace(/\n\s*/, ' ')}': ${
									sj
										.replace(/\n\s*/g, ' ')
										.replace(/\?$/, ``)
										.replace(/( extends infer .*)$/, `$1? 'True': 'False'`)
								};`,
						], [])
						.join(' ')
					}
				};`,
			`}>`].join(' ');

			// \`${JSON.stringify(h_struct).replace(/\\[tn"]/g, '')}\`>`;

			let b_asserted = true;

			if(h_struct[$ELSE]) {
				b_asserted = false;
				s_out = h_struct[$ELSE];
				delete h_struct[$ELSE];
			}

			for(let [sj_condition, z_actions] of ode(h_struct).reverse()) {
				let s_then = '';

				if('function' === typeof z_actions) {
					z_actions = z_actions(this);
				}

				if('string' === typeof z_actions) {
					s_then = z_actions;
				}
				else {
					this._nl_indent += 1;
					s_then = this.compile_struct(z_actions, [...a_path, sj_condition]);
					this._nl_indent -= 1;
				}

				s_out = this.if_(sj_condition, s_then, s_out, b_asserted? `Assertion ID: ${i_condition}`: '');
			}

			return s_out;
		}

		numeric(i_lo, i_hi=i_lo) {
			const a_chars = [];
			for(let i_num=i_lo; i_num<=i_hi; i_num++) {
				a_chars.push(`${i_num}`);
			}
			return a_chars.join('|');
		}

		valid(h_desc) {
			const a_out = [];
			for(const [si_key, w_value] of ode(h_desc)) {
				a_out.push(`${si_key}: ${stringify_ts(w_value)}`);
			}
			return `{${a_out.join(', ')}}`;
		}

		invalid(h_desc) {
			const a_out = [];
			for(const [si_key, sj_value] of ode(h_desc)) {
				a_out.push(`${si_key}:${sj_value}`);
			}
			return `Debug<string, {_message:\`Invalid ${this._s_language}; found in the "${this._si_production}" production\`, ${a_out.join(',')}}>`.replace(/\n/g, '\\n');
		}

		merge(si_var) {
			return h_append => `Merge<${this.valid(h_append)}, Cast<${si_var}, object>>`;
		}

		steps(a_steps) {
			return a_steps.join('\0');
		}
	}


	function grammar(fk_coder) {
		const a_out = [];
		const k_coder = new Coder('BCP-47 language tag');
		const h_grammar = fk_coder(k_coder);
		for(const [si_type, h_struct] of ode(h_grammar)) {
			k_coder._si_production =  si_type.replace(/\r?\n/g, '').replace(/^\s*([a-zA-Z0-9$_]+).*$/, '$1');
			a_out.push(`type ${si_type} = ${k_coder.compile_struct(h_struct)};`);
		}
		return a_out.join('\n\n');
	}

	function cache(a_sets, fk_sets=()=>({})) {
		return fk_sets(...a_sets);
	}

	function* patterns(g_types) {
		const {
			pure: a_pures=[],
			mixed: h_patterns={},
		} = g_types;

		for(const si_pure of a_pures) {
			yield `\ntype RTA_${si_pure}<a_input extends string[]> = Extends<a_input, ${si_pure}[]>;\n`;
			yield `\ntype RTS_${si_pure}<s_input extends string> = RTA_${si_pure}<Split<s_input>>;\n`;
		}

		const a_out = [];
		for(const [si_var, a_matches] of ode(h_patterns)) {
			const si_type = `R_${si_var}`;

			const nl_matches = a_matches.length;

			const a_cases = [
				'False',
				`Extends<String.At<s_input, 0>, ${a_matches[0]}>`,
			];

			for(let i_char=2; i_char<=nl_matches; i_char++) {
				a_cases.push([
					'And<',
					`	Extends<String.At<s_input, ${i_char-1}>, ${a_matches[i_char-1]}>,`,
					`	${si_type}<s_input>[${i_char-1}]`,
					'>',
				].join('\n\t'));
			}

			yield `\ntype ${si_type}<s_input extends string> = {${a_cases.map((s, i) => `\n\t${i}: ${s};`).join('')}\n};\n`;
		}
	}

	const join = a_parts => a_parts.join('\0');
}

@*{yield* patterns({
	pure: [
		'ALPHA',
		'DIGIT',
		'ALPHANUM',
	],
	// 'DIGIT': Array(3).fill('DIGIT'),
	// 'ALPHA': Array(8).fill('ALPHA'),
	// 'ALPHANUM': Array(8).fill('ALPHANUM'),
	mixed: {
		// 'DIGIT_ALPHANUM': [
		// 	'DIGIT',
		// 	...Array(3).fill('ALPHANUM'),
		// ],
	},
})}

@{`
type IRREGULAR = 
	| 'en-GB-oed'
	| 'i-ami'
	| 'i-bnn'
	| 'i-default'
	| 'i-enochian'
	| 'i-hak'
	| 'i-klingon'
	| 'i-lux'
	| 'i-mingo'
	| 'i-navajo'
	| 'i-pwn'
	| 'i-tao'
	| 'i-tay'
	| 'i-tsu'
	| 'sgn-BE-FR'
	| 'sgn-BE-NL'
	| 'sgn-CH-DE';

type REGULAR = 
	| 'art-lojban'
	| 'cel-gaulish'
	| 'no-bok'
	| 'no-nyn'
	| 'zh-guoyu'
	| 'zh-hakka'
	| 'zh-min'
	| 'zh-min'
	| 'zh-xiang';

type RTS_DIGIT_ALPHANUM<
	s_input extends string,
> = RTA_DIGIT_ALPHANUM<Split<s_input>>;

type RTA_DIGIT_ALPHANUM<
	a_input extends string[],
> = And<
	Extends<a_input[0], DIGIT>,
	Extends<List.Omit<a_input, 0>, ALPHANUM[]>
>;

type ExtensionStruct = {
	singleton: ALPHANUM;
	extensions: string[];
};

type Parsed = {
	_input: string;
	_normalized: string;
	_rest: string[];
	language: string;
	extendedLanguageSubtags: string[];
	script: string | null;
	region: string | null;
	variants: string[];
	extensions: ExtensionStruct[];
	privateuse: string[];
	regular: string | null;
	irregular: string | null;
};

type ParsedDefaults<
	g_set extends object={},
> = Merge<
	g_set,
	{
		_input: '';
		_normalized: '';
		_rest: [];
		language: '';
		extendedLanguageSubtags: [];
		script: null;
		region: null;
		variants: [];
		extensions: [];
		privateuse: [];
		regular: null;
		irregular: null;
	}
>;

type Finalize<
	g_init extends Parsed,
> = Omit<g_init, "_rest">;

type SetLanguage<
	s_language extends string=string,
> = {
	language: s_language;
};

type NestedExtensionsStruct = {
	_rest: string[];
	extensions: string[];
};

type NestedPrivateUsesStruct = {
	_rest: string[];
	privateuse: string[];
};
`}

@.{

	const G_ELSE_REST = ({
		[$ELSE]: 'Merge<{_rest: a_parts}, g_init>',
	});
}

@{grammar(k => ({
	[`Language<
		g_parsed extends Parsed,
		s_input extends string,
	>`]: {
		// length of input
		[k.assign('nl_input', `StrLen<s_input>`)]: cache([
			'Merge<SetLanguage<s_input>, Finalize<g_parsed>>',
			h_out => () => ({
				...h_out,
				[$ELSE]: k.invalid({
					_reason: `'Must match /[a-z]{2,8}/'`,
					language: 's_input',
				}),
			}),
		], (sj_valid, catch_) => catch_({
			// 2-5 chars
			[`nl_input extends ${numeric(2, 8)}`]: catch_({
				// 2*3 ALPHA: shortest ISO 639 code
				// 4ALPHA: reserved for future use
				// 5*8ALPHA: registered language subtag
				'RTS_ALPHA<s_input>?': sj_valid,
			}),
		})),
	},

	'Langtag<s_input extends string>': {
		[join([
			// s_lower := s_input.toLowerCase()
			k.assign_str('s_lower', 'Lowercase<s_input>'),

			// g_init := {_input: s_input} as Parsed
			...k.cassign('g_init<Parsed>', 'ParsedDefaults<{_input:s_input; _normalized:s_lower;}>'),
		])]: () => ({
			// grandfathered irregular
			's_lower extends IRREGULAR': 'Finalize<Merge<{irregular:s_lower}, g_init>>',

			// grandfathered regular
			's_lower extends REGULAR': 'Finalize<Merge<{regular:s_lower}, g_init>>',

			// split at first '-'
			's_lower extends `${infer s_part_0}-${infer s_rest}`': () => ({
				// 'x' privateuse
				's_part_0 extends "x"': () => ({
					[join([
						...k.cassign('g_parsed_privateuses<Parsed>', 'PrivateUse<g_init, Split<s_lower, "-">>'),
					])]: 'Finalize<g_parsed_privateuses>',
				}),

				// everything before '-'
				[k.assign('g_parsed_language', 'Language<g_init, s_part_0>')]: () => ({
					// valid language
					['g_parsed_language extends Parsed']: `LangtagAfterLanguage<
						g_parsed_language,
						s_rest
					>`,

					[$ELSE]: 'g_parsed_language',
				}),

				[$ELSE]: k.invalid({
					_reason: '`Unable to parse "${s_lower}"`',
				}),
			}),

			// no '-'
			[$ELSE]: 'Language<g_init, s_input>',
		}),
	},

	[`PrivateNames<
		g_parsed extends Parsed,
		s_privateuse extends string,
		a_parts extends string[],
	>`]: cache([
		{
			[$ELSE]: k.invalid({
				_reason: '`Must match /^x(-[a-z0-9]{1,8})+/`',
				privateuse: 's_privateuse',
			}),
		},
	], g_invalid => ({
		[`Extends<{
			[K in keyof a_parts]: a_parts[K] extends \`\${infer s_part}\`
				? And<
					Extends<StrLen<s_part>, ${k.numeric(1, 8)}>,
					RTS_ALPHA<s_part>
				>
				: False;
		}, 1[]>?`]: k.merge('g_parsed')({privateuse:'a_parts'}),

		...g_invalid,
	})),

	[`NestedPrivateUses<
		a_parts extends string[],
		a_prev extends string[]=[],
	>`]: cache([
		{
			[$ELSE]: `{
				_rest: a_parts;
				privateuse: a_prev;
			}`,
		},
	], g_else_rest => ({
		'a_parts[0] extends `${infer s_part}`': () => ({
			[`And<
				Extends<StrLen<s_part>, ${k.numeric(1, 8)}>,
				RTS_ALPHANUM<s_part>
			>?`]: `NestedPrivateUses<
				List.Omit<a_parts, 0>,
				[...a_prev, s_part]
			>`,
			...g_else_rest,
		}),
		...g_else_rest,
	})),

	[`PrivateUse<
		g_init extends Parsed,
		a_parts extends string[],
	>`]: {
		'a_parts[0] extends "x"': () => ({
			'a_parts[1] extends `${infer s_part_1}`': () => ({
				[$ASSERTIONS]: {
					input: 'a_parts',
				},
				[`And<
					Extends<StrLen<s_part_1>, ${k.numeric(1, 8)}>,
					RTS_ALPHANUM<s_part_1>
				>?`]: () => ({
					[$ASSERTIONS]: {
						input: 'a_parts',
					},
					[join([
						`NestedPrivateUses<
							List.Omit<a_parts, 0|1>
						> extends infer g_nested`,
						'g_nested extends NestedPrivateUsesStruct',
					])]: `Merge<
							{
								_rest: g_nested["_rest"];
								privateuse: [s_part_1, ...g_nested["privateuse"]];
							},
							g_init
						>`,
					// ...G_ELSE_REST,
				}),

				// [k.assign('a_parts', 'Split<s_name, "-">')]: 'PrivateNames<g_parsed, s_input, Cast<a_parts, string[]>>',
			}),
			// ...G_ELSE_REST,
			[$ELSE]: k.invalid({
				_reason: '`Must match /^x(-[a-z0-9]{1,8})+/`',
				privateuse: '`${a_parts[0]}-${a_parts[1]}`',
			}),
		}),
		...G_ELSE_REST,
	},

	[`ExtendedLanguageSubtags<
		g_init extends Parsed,
		a_parts extends string[],
		c_recursions extends number=0,
	>`]: {
		[`c_recursions extends ${k.numeric(0, 3)}`]: () => ({
			'a_parts[0] extends `${infer s_part}`': () => ({
				[`And<
					Equals<StrLen<s_part>, 3>,
					RTS_ALPHA<s_part>
				>?`]: `ExtendedLanguageSubtags<
					Merge<
						{
							extendedLanguageSubtags: [...g_init['extendedLanguageSubtags'], Cast<s_part, string>];
						},
						g_init
					>,
					List.Omit<a_parts, 0>,
					Add<c_recursions, 1>
				>`,
				...G_ELSE_REST,
			}),
			...G_ELSE_REST,
		}),
		[$ELSE]: k.invalid({
			_reason: '`Too many extended language subtags, expected at most 3 subtags`',
		}),
	},

	[`NestedExtensions<
		a_parts extends string[],
		a_prev extends string[]=[],
	>`]: cache([
		{
			[$ELSE]: `{
				_rest: a_parts;
				extensions: a_prev;
			}`,
		},
	], g_else_rest => ({
		'a_parts[0] extends `${infer s_part}`': () => ({
			[`And<
				Extends<StrLen<s_part>, ${k.numeric(2, 8)}>,
				RTS_ALPHANUM<s_part>
			>?`]: `NestedExtensions<
				List.Omit<a_parts, 0>,
				[...a_prev, s_part]
			>`,
			...g_else_rest,
		}),
		...g_else_rest,
	})),

	[`Extensions<
		g_init extends Parsed,
		a_parts extends string[],
	>`]: {
		'a_parts[0] extends SINGLETON': () => ({
			'a_parts[1] extends `${infer s_part_1}`': () => ({
				[`And<
					Extends<StrLen<s_part_1>, ${k.numeric(2, 8)}>,
					RTS_ALPHANUM<s_part_1>
				>?`]: () => ({
					[$ASSERTIONS]: {
						input: 'a_parts',
					},
					[join([
						`NestedExtensions<
							List.Omit<a_parts, 0|1>
						> extends infer g_nested`,
						'g_nested extends NestedExtensionsStruct',
					])]: `Extensions<
						Merge<
							{
								extensions: [
									...g_init["extensions"],
									{
										singleton: a_parts[0];
										extensions: [s_part_1, ...g_nested["extensions"]];
									},
								];
							},
							g_init
						>,
						g_nested["_rest"]
					>`,
					// ...G_ELSE_REST,
				}),
				...G_ELSE_REST,
			}),
			...G_ELSE_REST,
		}),
		...G_ELSE_REST,
	},


	[`Script<
		g_init extends Parsed,
		a_parts extends string[],
	>`]: {
		'a_parts[0] extends `${infer s_part}`': () => ({
			[`And<
				Equals<StrLen<s_part>, 4>,
				RTS_ALPHA<s_part>
			>?`]: `Merge<
				{
					_rest: List.Omit<a_parts, 0>;
					script: s_part;
				},
				g_init
			>`,
			[$ELSE]: 'g_init',
		}),
		[$ELSE]: 'g_init',
	},

	[`Region<
		g_init extends Parsed,
		a_parts extends string[],
	>`]: {
		'a_parts[0] extends `${infer s_part}`': () => ({
			[`And<
				Equals<StrLen<s_part>, 2>,
				RTS_ALPHA<s_part>
			>?`]: `Merge<
				{
					_rest: List.Omit<a_parts, 0>;
					region: s_part;
				},
				g_init
			>`,
			[`And<
				Equals<StrLen<s_part>, 3>,
				RTS_DIGIT<s_part>
			>?`]: `Merge<
				{
					_rest: List.Omit<a_parts, 0>;
					region: s_part;
				},
				g_init
			>`,
			[$ELSE]: 'g_init',
		}),
		[$ELSE]: 'g_init',
	},

	[`Variants<
		g_init extends Parsed,
		a_parts extends string[],
		c_recursions extends number=0,
	>`]: {
		...cache([
			`Variants<
					Merge<
						{
							variants: [...g_init['variants'], Cast<s_part, string>];
						},
						g_init
					>,
					List.Omit<a_parts, 0>,
					Add<c_recursions, 1>
				>`,
		], (sj_recurse) => ({
			'a_parts[0] extends `${infer s_part}`': () => ({
				// 5*8ALPHANUM
				[`And<
					Extends<StrLen<s_part>, ${k.numeric(5, 8)}>,
					RTS_ALPHANUM<s_part>
				>?`]: sj_recurse,

				// DIGIT 3ALPHANUM
				[`And<
					Equals<StrLen<s_part>, 4>,
					RTS_DIGIT_ALPHANUM<s_part>
				>?`]: sj_recurse,

				...G_ELSE_REST,
			}),
			...G_ELSE_REST,
		})),
	},

	[`LangtagAfterLanguage<
		g_init extends Parsed,
		s_input extends string,
	>`]: {
		[join([
			// a_lower := s_lower.split('-')
			k.assign('a_parts', 'Split<s_input, "-">'),

			// g_parsed := ExtendedLanguageSubtags(g_init, a_parts)
			...k.cassign('g_parsed<Parsed>', 'ExtendedLanguageSubtags<g_init, Cast<a_parts, string[]>>'),

			// a_rest := g_parsed.rest
			k.assign('a_rest', 'g_parsed["_rest"]'),

			// g_parsed_script := Script(a_rest)
			...k.cassign('g_parsed_script<Parsed>', 'Script<g_parsed, Cast<a_rest, string[]>>'),

			// a_rest_script := g_parsed_script.rest
			k.assign('a_rest_script', 'g_parsed_script["_rest"]'),

			// g_parsed_region := Region(a_rest_script)
			...k.cassign('g_parsed_region<Parsed>', 'Region<g_parsed_script, Cast<a_rest_script, string[]>>'),

			// a_rest_region := g_parsed_region.rest
			k.assign('a_rest_region', 'g_parsed_region["_rest"]'),

			// g_parsed_variant := Variant(a_rest_region)
			...k.cassign('g_parsed_variant<Parsed>', 'Variants<g_parsed_region, Cast<a_rest_region, string[]>>'),

			// a_rest_variant := g_parsed_variant.rest
			k.assign('a_rest_variant', 'g_parsed_variant["_rest"]'),

			// g_parsed_extensions := Extensions(a_rest_variant)
			...k.cassign('g_parsed_extensions<Parsed>', 'Extensions<g_parsed_variant, Cast<a_rest_variant, string[]>>'),

			// a_rest_extensions := g_parsed_extensions.rest
			k.assign('a_rest_extensions', 'g_parsed_extensions["_rest"]'),

			// g_parsed_privateuses := PrivateUse(a_rest_extensions)
			...k.cassign('g_parsed_privateuses<Parsed>', 'PrivateUse<g_parsed_extensions, Cast<a_rest_extensions, string[]>>'),

			// a_rest_privateuses := g_parsed_privateuses.rest
			...k.cassign('a_rest_privateuses<string[]>', 'g_parsed_privateuses["_rest"]'),
		])]: () => ({
			'a_rest_privateuses["length"] extends 0': 'Finalize<g_parsed_privateuses>',

			[$ELSE]: k.invalid({
				_reason: '`Unable to match text at the end: ${Join<a_rest_privateuses, "-">}`',
			}),
		}),
	},
}))}

{
	/* eslint-disable @typescript-eslint/no-unused-vars */
	@//@

	@*{
		const A_FIXTURES = [
			'aa-111','aa-7-123abc-abc-a-12','aa-b1b1b-6a8b-cccccc','aa-b1b1b','aa-bb','aa-bbb-ccc-1111-ccccc-b1b1b','aa-bbb-ccc-ddd','aa-bbb','aa-bbbb-cc','aa-bbbb','aa-x-1234ab-d','aa',
			'aaa-bbb-ccc-ddd-abcd-123-abc123-0abc-b-01-abc123-x-01ab-abc12','aaa-bbb-ccc','aaaa','aaaaa','aaaaaa','aaaaaaa','aaaaaaaa','afb','ar-afb','art-lojban','ast','az-Arab-x-AZE-derbend','az-Latn',
			'cel-gaulish','cmn-Hans-CN','de-CH-1901','de-CH-x-phonebk','de-DE-u-co-phonebk','de-DE','de-Qaaa','de','en-GB-oed','en-US-u-islamcal','en-US-x-twain','en-US','en-a-myext-b-another','en',
			'es-005','es-419','fr-CA','fr','hak','hy-Latn-IT-arevela','i-ami','i-bnn','i-default','i-enochian','i-hak','i-klingon','i-lux','i-mingo','i-navajo','i-pwn','i-tao','i-tay','i-tsu','ja','mas',
			'no-bok','no-nyn','qaa-Qaaa-QM-x-southern','sgn-BE-FR','sgn-BE-NL','sgn-CH-DE','sl-IT-nedis','sl-nedis','sl-rozaj-biske','sl-rozaj','sr-Cyrl','sr-Latn-QM','sr-Latn-RS','sr-Latn','sr-Qaaa-RS',
			'x-111-aaaaa-BBB','x-whatever','yue-HK','zh-CN-a-myext-x-private','zh-Hans-CN','zh-Hans','zh-Hant-HK','zh-Hant','zh-cmn-Hans-CN','zh-guoyu','zh-hakka','zh-min-nan','zh-min','zh-xiang',
			'zh-yue-HK','zh-yue',
		].map(s => `*${s}`);

		const G_CASES = {
			...A_FIXTURES.reduce((h_out, si_fixture) => ({
				...h_out,
				[si_fixture]: {
					comment: 'auto-generated from bcp-47 test directory',
				},
			}), {}),
		};

		for(const [si_case, gc_case] of ode(G_CASES)) {
			const sx_case = si_case.replace(/^\*/, '');

			const sj_hash = plainify({
				...bcp47.parse(sx_case),
				_input: sx_case,
				_normalized: sx_case,
			}, {
				filter([si_key, z_value]) {
					// if(!z_value) return false
					// if(Array.isArray(z_value)) return z_value.length;
					return true;
				},
			});

			const sj_test = `Langtag<'${sx_case}'>`;
			const si_assert = sx_case.replace(/[^a-z0-9]/g, '_');

			yield [
				...(gc_case.comment? [`// ${gc_case.comment}`]: []),
				`const ${si_assert}: ASSERT_SAME<${sj_test}, {${sj_hash}}> = 1;`,
			].map(s => s+'\n').join('')+'\n';

			if('*' === si_case[0]){
				yield `type DEBUG_${si_assert} = ${sj_test};\n`;
			}
		}
	}
}


export type {
	Langtag,
};
