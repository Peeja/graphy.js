import stream from 'readable-stream';


function Stream$bucket(s_encoding='utf8') {
	const g_readable = this._readableState;

	// async operation
	return new Promise((fk_bucket, fe_bucket) => {
		// writable descriptor
		let gc_writable = null;

		// object mode
		if(g_readable.objectMode) {
			const a_data = [];

			// create writable
			gc_writable = {
				write(w_event, s_write_encoding, fk_write) {
					a_data.push(w_event);
					fk_write();
				},

				writev(a_chunks, fk_writev) {
					a_data.push(...a_chunks);
					fk_writev();
				},
			};
		}
		// utf8-encoded strings
		else if('utf8' === s_encoding || 'utf-8' === s_encoding) {
			let s_data = '';

			// set encoding
			this.setEncoding(s_encoding);

			// create writable
			gc_writable = {
				decodeStrings: false,

				write(s_chunk, s_write_encoding, fk_write) {
					s_data += s_chunk;
					fk_write();
				},

				writev(a_chunks, fk_writev) {
					s_data += a_chunks.join('');
					fk_writev();
				},
			};
		}
		// buffer
		else if('buffer' === s_encoding) {
			let ab_data = Buffer.from([]);

			// create writable
			gc_writable = {
				decodeStrings: true,

				write(ab_chunk, s_write_encoding, fk_write) {
					ab_data = Buffer.concat([ab_data, ab_chunk], ab_data.length+ab_chunk.length);
					fk_write();
				},
			};
		}
		// anything else
		else {
			const a_data = [];

			// create writable
			gc_writable = {
				write(w_event, s_write_encoding, fk_write) {
					a_data.push(w_event);
					fk_write();
				},

				writev(a_chunks, fk_writev) {
					a_data.push(...a_chunks);
					fk_writev();
				},
			};
		}

		// writable options set
		if(gc_writable) {
			// pipe to writable
			return this.pipe(new stream.Writable(gc_writable))
				// error
				.on('error', (e_stream) => {
					fe_bucket(e_stream);
				})
				// wait for it to finish
				.on('finish', () => {
					fk_bucket(a_data);
				});
		}

		return fe_bucket(`Unable to deduce stream's encoding`);
	});
}

function Stream$import(ds_source) {
	ds_source
		.on('data', w_chunk => this.write(w_chunk))
		.on('end', () => this.end())
		.on('error', e_read => this.emit('error', e_read));

	return this;
}
Readable.prototype.import = Stream$import;

@//@
export class Readable extends stream.Readable {
	static fromData(w_push, s_encoding=null) {
		// encoding not explicit, string given; assume utf8
		if(!s_encoding && 'string' === typeof w_push) s_encoding = 'utf8';

		// readable
		return new Readable({
			objectMode: !s_encoding && 'string' !== typeof w_push && !Buffer.isBuffer(w_push),

			read() {
				this.push(w_push, s_encoding);
				this.push(null);
			},
		});
	}
}
Readable.prototype.bucket = Stream$bucket;



export class Writable extends stream.Writable {}
Writable.prototype.import = Stream$import;

export class Duplex extends stream.Duplex {}
Duplex.prototype.bucket = Stream$bucket;

export class Transform extends stream.Transform {
	demolish(e_destroy) {
		// do not allow to push
		this.push = (z_chunk) => {
			// ignore eof signals from node core
			if(null === z_chunk) return;

			// anything else is bad
			throw new Error(`[ERR_STREAM_DESTROYED]: Cannot push after stream was destroyed`);
		};

		// do not allow to emit 'end'
		this.emit = function(s_event, ...a_args) {
			if('end' === s_event) return;

			Object.getPrototypeOf(this).emit.apply(this, [s_event, ...a_args]);
		};

		// an error was given, destroy the stream as well
		if(e_destroy) {
			return stream.Transform.prototype.destroy.call(this, e_destroy);
		}
	}
}
Transform.prototype.import = Stream$import;
Transform.prototype.bucket = Stream$bucket;

export class QuadsToOther extends Transform {
	constructor(gc_transform={}) {
		super({
			...gc_transform,
			writableObjectMode: true,
			readableObjectMode: true,
		});

		this._as_inputs = new Set();

		// forward prefix and comment events
		this.on('pipe', (ds_src) => {
			this._as_inputs.add(ds_src);

			ds_src
				.on('prefix', (...a_args) => {
					this.emit('prefix', ...a_args);
				})
				.on('comment', (...a_args) => {
					this.emit('comment', ...a_args);
				});
		});

		this.on('unpipe', (ds_src) => {
			this._as_inputs.delete(ds_src);
		});
	}

	_destroy() {
		for(let ds_input of this._as_inputs) {
			ds_input.destroy();
		}
	}
}

export class QuadsToJsonTransform extends QuadsToOther {
	// serializse json
	_transform(g_quad, s_encoding, fk_transform) {
		fk_transform(null, JSON.stringify(g_quad.isolate())+'\n');
	}
}

export class QuadsToWritable extends QuadsToOther {
	_transform(g_quad, s_encoding, fk_transform) {
		fk_transform(null, {
			type: 'quad',
			value: g_quad,
		});
	}
}

Transform.QuadsToOther = QuadsToOther;



const {
	Stream,
	PassThrough,
	finished,
	pipeline,
} = stream;

export {
	Stream,
	PassThrough,
	finished,
	pipeline,
};

export default {
	Readable,
	Writable,
	Duplex,
	Transform,
	QuadsToOther,
	QuadsToJsonTransform,
	QuadsToWritable,
	Stream,
	PassThrough,
	finished,
	pipeline,
};
